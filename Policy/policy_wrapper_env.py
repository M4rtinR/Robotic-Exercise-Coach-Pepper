import logging
import gym
from gym import spaces
import numpy as np
from typing import Optional
# from gym.utils.renderer import Renderer

from Policy.policy import Policy


class PolicyWrapper(gym.Env):
    """
    A class which acts as an interface between the raw policy and the behaviour tree. It can give the tree a behaviour
    or observation generated by the policy which is within a set of defined valid behaviours for a given state.
    ...
    Attributes
    ----------
    Goal Levels :type int
        6 different goal levels which correspond to stages in the interaction and the goal hierarchy of the racketware
        guide.
    Phases :type int
        2 different phases (start and end) which correspond respectively to either an intro or feedback sequence.
    Performance Levels :type int
        8 different performance levels which represent how the user did in their previous action.
    policy
        The policy we will query to obtain behaviours and observations.

    Methods
    -------
    get_behaviour(state, goal_level, performance, phase)
        Obtain a behaviour from the underlying policy and check it is valid in the current state of interaction.
    _get_valid_list(goal_level, performance, phase)
        Local method which creates the list of valid for each state of interaction.
    get_observation(state, behaviour)
        Obtain an observation from the underlying policy.
    """
    def __init__(self, policy, render_mode: Optional[str] = None):
        self.policy = policy
        # TODO: Observation will also have to include user performance because this is needed to calculate reward.
        self.observation_space = spaces.Discrete(69)
        self.action_space = spaces.Discrete(68)  # All the possible states but without A_START

    def get_observation(self, state, behaviour):
        """
        Obtain an observation from the underlying policy.
        :param state :type int: the previously observed state.
        :param behaviour :type int: the previous behaviour generated by the policy.
        :return:type int: the observation of which state we have moved to, generated by the policy.
        """
        return self.policy.sample_observation(state, behaviour)

    def reset(self, seed=None, return_info=False, options=None):
        # Will be called when the "done" signal has been issued. So write current policy to a file to be used next time.
        super().reset(seed=seed)

        observation = Policy.A_END
        info = "End of session (episode)."

        return (observation, info) if return_info else observation

    def step(self, action):
        # This will trigger FormatAction etc until observation has been given (DisplayBehaviour I think), then will
        # decide on reward based on the observation.
        return None, None, None, None
